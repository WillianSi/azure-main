{"ast":null,"code":"/*\n * Copyright (c) Microsoft Corporation.\n * Licensed under the MIT License.\n *\n * Code generated by Microsoft (R) AutoRest Code Generator.\n * Changes may cause incorrect behavior and will be lost if the code is regenerated.\n */","map":{"version":3,"mappings":"AAAA","names":[],"sources":["C:\\Users\\willi\\Downloads\\azure-main\\node_modules\\@azure\\cognitiveservices-computervision\\src\\models\\index.ts"],"sourcesContent":["/*\n * Copyright (c) Microsoft Corporation.\n * Licensed under the MIT License.\n *\n * Code generated by Microsoft (R) AutoRest Code Generator.\n * Changes may cause incorrect behavior and will be lost if the code is regenerated.\n */\n\n\nimport * as msRest from \"@azure/ms-rest-js\";\n\n/**\n * An object describing face rectangle.\n */\nexport interface FaceRectangle {\n  /**\n   * X-coordinate of the top left point of the face, in pixels.\n   */\n  left?: number;\n  /**\n   * Y-coordinate of the top left point of the face, in pixels.\n   */\n  top?: number;\n  /**\n   * Width measured from the top-left point of the face, in pixels.\n   */\n  width?: number;\n  /**\n   * Height measured from the top-left point of the face, in pixels.\n   */\n  height?: number;\n}\n\n/**\n * An object describing possible celebrity identification.\n */\nexport interface CelebritiesModel {\n  /**\n   * Name of the celebrity.\n   */\n  name?: string;\n  /**\n   * Confidence level for the celebrity recognition as a value ranging from 0 to 1.\n   */\n  confidence?: number;\n  /**\n   * Location of the identified face in the image.\n   */\n  faceRectangle?: FaceRectangle;\n}\n\n/**\n * A landmark recognized in the image.\n */\nexport interface LandmarksModel {\n  /**\n   * Name of the landmark.\n   */\n  name?: string;\n  /**\n   * Confidence level for the landmark recognition as a value ranging from 0 to 1.\n   */\n  confidence?: number;\n}\n\n/**\n * An object describing additional category details.\n */\nexport interface CategoryDetail {\n  /**\n   * An array of celebrities if any identified.\n   */\n  celebrities?: CelebritiesModel[];\n  /**\n   * An array of landmarks if any identified.\n   */\n  landmarks?: LandmarksModel[];\n}\n\n/**\n * An object describing identified category.\n */\nexport interface Category {\n  /**\n   * Name of the category.\n   */\n  name?: string;\n  /**\n   * Scoring of the category.\n   */\n  score?: number;\n  /**\n   * Details of the identified category.\n   */\n  detail?: CategoryDetail;\n}\n\n/**\n * An object describing whether the image contains adult-oriented content and/or is racy.\n */\nexport interface AdultInfo {\n  /**\n   * A value indicating if the image contains adult-oriented content.\n   */\n  isAdultContent?: boolean;\n  /**\n   * A value indicating if the image is racy.\n   */\n  isRacyContent?: boolean;\n  /**\n   * A value indicating if the image is gory.\n   */\n  isGoryContent?: boolean;\n  /**\n   * Score from 0 to 1 that indicates how much the content is considered adult-oriented within the\n   * image.\n   */\n  adultScore?: number;\n  /**\n   * Score from 0 to 1 that indicates how suggestive is the image.\n   */\n  racyScore?: number;\n  /**\n   * Score from 0 to 1 that indicates how gory is the image.\n   */\n  goreScore?: number;\n}\n\n/**\n * An object providing additional metadata describing color attributes.\n */\nexport interface ColorInfo {\n  /**\n   * Possible dominant foreground color.\n   */\n  dominantColorForeground?: string;\n  /**\n   * Possible dominant background color.\n   */\n  dominantColorBackground?: string;\n  /**\n   * An array of possible dominant colors.\n   */\n  dominantColors?: string[];\n  /**\n   * Possible accent color.\n   */\n  accentColor?: string;\n  /**\n   * A value indicating if the image is black and white.\n   */\n  isBWImg?: boolean;\n}\n\n/**\n * An object providing possible image types and matching confidence levels.\n */\nexport interface ImageType {\n  /**\n   * Confidence level that the image is a clip art.\n   */\n  clipArtType?: number;\n  /**\n   * Confidence level that the image is a line drawing.\n   */\n  lineDrawingType?: number;\n}\n\n/**\n * An entity observation in the image, along with the confidence score.\n */\nexport interface ImageTag {\n  /**\n   * Name of the entity.\n   */\n  name?: string;\n  /**\n   * The level of confidence that the entity was observed.\n   */\n  confidence?: number;\n  /**\n   * Optional hint/details for this tag.\n   */\n  hint?: string;\n}\n\n/**\n * An image caption, i.e. a brief description of what the image depicts.\n */\nexport interface ImageCaption {\n  /**\n   * The text of the caption.\n   */\n  text?: string;\n  /**\n   * The level of confidence the service has in the caption.\n   */\n  confidence?: number;\n}\n\n/**\n * A collection of content tags, along with a list of captions sorted by confidence level, and\n * image metadata.\n */\nexport interface ImageDescriptionDetails {\n  /**\n   * A collection of image tags.\n   */\n  tags?: string[];\n  /**\n   * A list of captions, sorted by confidence level.\n   */\n  captions?: ImageCaption[];\n}\n\n/**\n * An object describing a face identified in the image.\n */\nexport interface FaceDescription {\n  /**\n   * Possible age of the face.\n   */\n  age?: number;\n  /**\n   * Possible gender of the face. Possible values include: 'Male', 'Female'\n   */\n  gender?: Gender;\n  /**\n   * Rectangle in the image containing the identified face.\n   */\n  faceRectangle?: FaceRectangle;\n}\n\n/**\n * A bounding box for an area inside an image.\n */\nexport interface BoundingRect {\n  /**\n   * X-coordinate of the top left point of the area, in pixels.\n   */\n  x?: number;\n  /**\n   * Y-coordinate of the top left point of the area, in pixels.\n   */\n  y?: number;\n  /**\n   * Width measured from the top-left point of the area, in pixels.\n   */\n  w?: number;\n  /**\n   * Height measured from the top-left point of the area, in pixels.\n   */\n  h?: number;\n}\n\n/**\n * An object detected inside an image.\n */\nexport interface ObjectHierarchy {\n  /**\n   * Label for the object.\n   */\n  object?: string;\n  /**\n   * Confidence score of having observed the object in the image, as a value ranging from 0 to 1.\n   */\n  confidence?: number;\n  /**\n   * The parent object, from a taxonomy perspective.\n   * The parent object is a more generic form of this object.  For example, a 'bulldog' would have\n   * a parent of 'dog'.\n   */\n  parent?: ObjectHierarchy;\n}\n\n/**\n * An object detected in an image.\n */\nexport interface DetectedObject {\n  /**\n   * Approximate location of the detected object.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly rectangle?: BoundingRect;\n  /**\n   * Label for the object.\n   */\n  object?: string;\n  /**\n   * Confidence score of having observed the object in the image, as a value ranging from 0 to 1.\n   */\n  confidence?: number;\n  /**\n   * The parent object, from a taxonomy perspective.\n   * The parent object is a more generic form of this object.  For example, a 'bulldog' would have\n   * a parent of 'dog'.\n   */\n  parent?: ObjectHierarchy;\n}\n\n/**\n * A brand detected in an image.\n */\nexport interface DetectedBrand {\n  /**\n   * Label for the brand.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly name?: string;\n  /**\n   * Confidence score of having observed the brand in the image, as a value ranging from 0 to 1.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly confidence?: number;\n  /**\n   * Approximate location of the detected brand.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly rectangle?: BoundingRect;\n}\n\n/**\n * Image metadata.\n */\nexport interface ImageMetadata {\n  /**\n   * Image width, in pixels.\n   */\n  width?: number;\n  /**\n   * Image height, in pixels.\n   */\n  height?: number;\n  /**\n   * Image format.\n   */\n  format?: string;\n}\n\n/**\n * Result of AnalyzeImage operation.\n */\nexport interface ImageAnalysis {\n  /**\n   * An array indicating identified categories.\n   */\n  categories?: Category[];\n  /**\n   * An object describing whether the image contains adult-oriented content and/or is racy.\n   */\n  adult?: AdultInfo;\n  /**\n   * An object providing additional metadata describing color attributes.\n   */\n  color?: ColorInfo;\n  /**\n   * An object providing possible image types and matching confidence levels.\n   */\n  imageType?: ImageType;\n  /**\n   * A list of tags with confidence level.\n   */\n  tags?: ImageTag[];\n  /**\n   * A collection of content tags, along with a list of captions sorted by confidence level, and\n   * image metadata.\n   */\n  description?: ImageDescriptionDetails;\n  /**\n   * An array of possible faces within the image.\n   */\n  faces?: FaceDescription[];\n  /**\n   * Array of objects describing what was detected in the image.\n   */\n  objects?: DetectedObject[];\n  /**\n   * Array of brands detected in the image.\n   */\n  brands?: DetectedBrand[];\n  /**\n   * Id of the REST API request.\n   */\n  requestId?: string;\n  metadata?: ImageMetadata;\n  modelVersion?: string;\n}\n\n/**\n * A collection of content tags, along with a list of captions sorted by confidence level, and\n * image metadata.\n */\nexport interface ImageDescription {\n  /**\n   * A collection of image tags.\n   */\n  tags?: string[];\n  /**\n   * A list of captions, sorted by confidence level.\n   */\n  captions?: ImageCaption[];\n  /**\n   * Id of the REST API request.\n   */\n  requestId?: string;\n  metadata?: ImageMetadata;\n  modelVersion?: string;\n}\n\n/**\n * Result of a DetectImage call.\n */\nexport interface DetectResult {\n  /**\n   * An array of detected objects.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly objects?: DetectedObject[];\n  /**\n   * Id of the REST API request.\n   */\n  requestId?: string;\n  metadata?: ImageMetadata;\n  modelVersion?: string;\n}\n\n/**\n * An object describing supported model by name and categories.\n */\nexport interface ModelDescription {\n  /**\n   * The name of the model.\n   */\n  name?: string;\n  /**\n   * Categories of the model.\n   */\n  categories?: string[];\n}\n\n/**\n * Result of the List Domain Models operation.\n */\nexport interface ListModelsResult {\n  /**\n   * An array of supported models.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly modelsProperty?: ModelDescription[];\n}\n\n/**\n * Result of image analysis using a specific domain model including additional metadata.\n */\nexport interface DomainModelResults {\n  /**\n   * Model-specific response.\n   */\n  result?: any;\n  /**\n   * Id of the REST API request.\n   */\n  requestId?: string;\n  metadata?: ImageMetadata;\n  modelVersion?: string;\n}\n\n/**\n * Information on a recognized word.\n */\nexport interface OcrWord {\n  /**\n   * Bounding box of a recognized word. The four integers represent the x-coordinate of the left\n   * edge, the y-coordinate of the top edge, width, and height of the bounding box, in the\n   * coordinate system of the input image, after it has been rotated around its center according to\n   * the detected text angle (see textAngle property), with the origin at the top-left corner, and\n   * the y-axis pointing down.\n   */\n  boundingBox?: string;\n  /**\n   * String value of a recognized word.\n   */\n  text?: string;\n}\n\n/**\n * An object describing a single recognized line of text.\n */\nexport interface OcrLine {\n  /**\n   * Bounding box of a recognized line. The four integers represent the x-coordinate of the left\n   * edge, the y-coordinate of the top edge, width, and height of the bounding box, in the\n   * coordinate system of the input image, after it has been rotated around its center according to\n   * the detected text angle (see textAngle property), with the origin at the top-left corner, and\n   * the y-axis pointing down.\n   */\n  boundingBox?: string;\n  /**\n   * An array of objects, where each object represents a recognized word.\n   */\n  words?: OcrWord[];\n}\n\n/**\n * A region consists of multiple lines (e.g. a column of text in a multi-column document).\n */\nexport interface OcrRegion {\n  /**\n   * Bounding box of a recognized region. The four integers represent the x-coordinate of the left\n   * edge, the y-coordinate of the top edge, width, and height of the bounding box, in the\n   * coordinate system of the input image, after it has been rotated around its center according to\n   * the detected text angle (see textAngle property), with the origin at the top-left corner, and\n   * the y-axis pointing down.\n   */\n  boundingBox?: string;\n  /**\n   * An array of recognized lines of text.\n   */\n  lines?: OcrLine[];\n}\n\n/**\n * An interface representing OcrResult.\n */\nexport interface OcrResult {\n  /**\n   * The BCP-47 language code of the text in the image.\n   */\n  language?: string;\n  /**\n   * The angle, in radians, of the detected text with respect to the closest horizontal or vertical\n   * direction. After rotating the input image clockwise by this angle, the recognized text lines\n   * become horizontal or vertical. In combination with the orientation property it can be used to\n   * overlay recognition results correctly on the original image, by rotating either the original\n   * image or recognition results by a suitable angle around the center of the original image. If\n   * the angle cannot be confidently detected, this property is not present. If the image contains\n   * text at different angles, only part of the text will be recognized correctly.\n   */\n  textAngle?: number;\n  /**\n   * Orientation of the text recognized in the image, if requested. The value (up, down, left, or\n   * right) refers to the direction that the top of the recognized text is facing, after the image\n   * has been rotated around its center according to the detected text angle (see textAngle\n   * property).\n   * If detection of the orientation was not requested, or no text is detected, the value is\n   * 'NotDetected'.\n   */\n  orientation?: string;\n  /**\n   * An array of objects, where each object represents a region of recognized text.\n   */\n  regions?: OcrRegion[];\n  modelVersion?: string;\n}\n\n/**\n * The results of a image tag operation, including any tags and image metadata.\n */\nexport interface TagResult {\n  /**\n   * A list of tags with confidence level.\n   */\n  tags?: ImageTag[];\n  /**\n   * Id of the REST API request.\n   */\n  requestId?: string;\n  metadata?: ImageMetadata;\n  modelVersion?: string;\n}\n\n/**\n * Result of AreaOfInterest operation.\n */\nexport interface AreaOfInterestResult {\n  /**\n   * A bounding box for an area of interest inside an image.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly areaOfInterest?: BoundingRect;\n  /**\n   * Id of the REST API request.\n   */\n  requestId?: string;\n  metadata?: ImageMetadata;\n  modelVersion?: string;\n}\n\n/**\n * An interface representing ImageUrl.\n */\nexport interface ImageUrl {\n  /**\n   * Publicly reachable URL of an image.\n   */\n  url: string;\n}\n\n/**\n * Details about the API request error.\n */\nexport interface ComputerVisionInnerError {\n  /**\n   * The error code. Possible values include: 'InvalidImageFormat', 'UnsupportedMediaType',\n   * 'InvalidImageUrl', 'NotSupportedFeature', 'NotSupportedImage', 'Timeout',\n   * 'InternalServerError', 'InvalidImageSize', 'BadArgument', 'DetectFaceError',\n   * 'NotSupportedLanguage', 'InvalidThumbnailSize', 'InvalidDetails', 'InvalidModel',\n   * 'CancelledRequest', 'NotSupportedVisualFeature', 'FailedToProcess', 'Unspecified',\n   * 'StorageException'\n   */\n  code: ComputerVisionInnerErrorCodeValue;\n  /**\n   * Error message.\n   */\n  message: string;\n}\n\n/**\n * The API request error.\n */\nexport interface ComputerVisionError {\n  /**\n   * The error code. Possible values include: 'InvalidRequest', 'InvalidArgument',\n   * 'InternalServerError', 'ServiceUnavailable'\n   */\n  code: ComputerVisionErrorCodes;\n  /**\n   * A message explaining the error reported by the service.\n   */\n  message: string;\n  /**\n   * Inner error contains more specific information.\n   */\n  innererror?: ComputerVisionInnerError;\n}\n\n/**\n * The API error response.\n */\nexport interface ComputerVisionErrorResponse {\n  /**\n   * Error contents.\n   */\n  error: ComputerVisionError;\n}\n\n/**\n * An object representing the style of the text line.\n */\nexport interface Style {\n  /**\n   * The text line style name, including handwriting and other. Possible values include: 'other',\n   * 'handwriting'\n   */\n  name: TextStyle;\n  /**\n   * The confidence of text line style.\n   */\n  confidence: number;\n}\n\n/**\n * An object representing the appearance of the text line.\n */\nexport interface Appearance {\n  /**\n   * An object representing the style of the text line.\n   */\n  style: Style;\n}\n\n/**\n * An object representing a recognized word.\n */\nexport interface Word {\n  /**\n   * Bounding box of a recognized word.\n   */\n  boundingBox: number[];\n  /**\n   * The text content of the word.\n   */\n  text: string;\n  /**\n   * Qualitative confidence measure.\n   */\n  confidence: number;\n}\n\n/**\n * An object representing a recognized text line.\n */\nexport interface Line {\n  /**\n   * The BCP-47 language code of the recognized text line. Only provided where the language of the\n   * line differs from the page's.\n   */\n  language?: string;\n  /**\n   * Bounding box of a recognized line.\n   */\n  boundingBox: number[];\n  /**\n   * Appearance of the text line.\n   */\n  appearance?: Appearance;\n  /**\n   * The text content of the line.\n   */\n  text: string;\n  /**\n   * List of words in the text line.\n   */\n  words: Word[];\n}\n\n/**\n * Text extracted from a page in the input document.\n */\nexport interface ReadResult {\n  /**\n   * The 1-based page number of the recognition result.\n   */\n  page: number;\n  /**\n   * The BCP-47 language code of the recognized text page.\n   */\n  language?: string;\n  /**\n   * The orientation of the image in degrees in the clockwise direction. Range between [-180, 180).\n   */\n  angle: number;\n  /**\n   * The width of the image in pixels or the PDF in inches.\n   */\n  width: number;\n  /**\n   * The height of the image in pixels or the PDF in inches.\n   */\n  height: number;\n  /**\n   * The unit used in the Width, Height and BoundingBox. For images, the unit is 'pixel'. For PDF,\n   * the unit is 'inch'. Possible values include: 'pixel', 'inch'\n   */\n  unit: TextRecognitionResultDimensionUnit;\n  /**\n   * A list of recognized text lines.\n   */\n  lines: Line[];\n}\n\n/**\n * Analyze batch operation result.\n */\nexport interface AnalyzeResults {\n  /**\n   * Version of schema used for this result.\n   */\n  version: string;\n  /**\n   * Version of the OCR model used for text extraction.\n   */\n  modelVersion: string;\n  /**\n   * Text extracted from the input.\n   */\n  readResults: ReadResult[];\n}\n\n/**\n * OCR result of the read operation.\n */\nexport interface ReadOperationResult {\n  /**\n   * Status of the read operation. Possible values include: 'notStarted', 'running', 'failed',\n   * 'succeeded'\n   */\n  status?: OperationStatusCodes;\n  /**\n   * Get UTC date time the batch operation was submitted.\n   */\n  createdDateTime?: string;\n  /**\n   * Get last updated UTC date time of this batch operation.\n   */\n  lastUpdatedDateTime?: string;\n  /**\n   * Analyze batch operation result.\n   */\n  analyzeResult?: AnalyzeResults;\n}\n\n/**\n * Details about the API request error.\n */\nexport interface ComputerVisionOcrError {\n  /**\n   * The error code.\n   */\n  code: any;\n  /**\n   * A message explaining the error reported by the service.\n   */\n  message: string;\n  /**\n   * A unique request identifier.\n   */\n  requestId?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientAnalyzeImageOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * A string indicating what visual feature types to return. Multiple values should be\n   * comma-separated. Valid visual feature types include: Categories - categorizes image content\n   * according to a taxonomy defined in documentation. Tags - tags the image with a detailed list\n   * of words related to the image content. Description - describes the image content with a\n   * complete English sentence. Faces - detects if faces are present. If present, generate\n   * coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color\n   * - determines the accent color, dominant color, and whether an image is black&white. Adult -\n   * detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory\n   * (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also\n   * detected. Objects - detects various objects within an image, including the approximate\n   * location. The Objects argument is only available in English. Brands - detects various brands\n   * within an image, including the approximate location. The Brands argument is only available in\n   * English.\n   */\n  visualFeatures?: VisualFeatureTypes[];\n  /**\n   * A string indicating which domain-specific details to return. Multiple values should be\n   * comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if\n   * detected in the image, Landmarks - identifies notable landmarks in the image.\n   */\n  details?: Details[];\n  /**\n   * The desired language for output generation. If this parameter is not specified, the default\n   * value is \"en\". See https://aka.ms/cv-languages for list of supported languages. Possible\n   * values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n   * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n   * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'. Default value:\n   * 'en'.\n   */\n  language?: Language;\n  /**\n   * Turn off specified domain models when generating the description.\n   */\n  descriptionExclude?: DescriptionExclude[];\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientDescribeImageOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * Maximum number of candidate descriptions to be returned.  The default is 1. Default value: 1.\n   */\n  maxCandidates?: number;\n  /**\n   * The desired language for output generation. If this parameter is not specified, the default\n   * value is \"en\". See https://aka.ms/cv-languages for list of supported languages. Possible\n   * values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n   * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n   * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'. Default value:\n   * 'en'.\n   */\n  language?: Language1;\n  /**\n   * Turn off specified domain models when generating the description.\n   */\n  descriptionExclude?: DescriptionExclude[];\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientDetectObjectsOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientAnalyzeImageByDomainOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * The desired language for output generation. If this parameter is not specified, the default\n   * value is \"en\". See https://aka.ms/cv-languages for list of supported languages. Possible\n   * values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n   * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n   * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'. Default value:\n   * 'en'.\n   */\n  language?: Language2;\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientRecognizePrintedTextOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.\n   * Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr',\n   * 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro',\n   * 'sr-Cyrl', 'sr-Latn', 'sk'. Default value: 'unk'.\n   */\n  language?: OcrLanguages;\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientTagImageOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * The desired language for output generation. If this parameter is not specified, the default\n   * value is \"en\". See https://aka.ms/cv-languages for list of supported languages. Possible\n   * values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n   * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n   * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'. Default value:\n   * 'en'.\n   */\n  language?: Language3;\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientGenerateThumbnailOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * Boolean flag for enabling smart cropping. Default value: false.\n   */\n  smartCropping?: boolean;\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientGetAreaOfInterestOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientReadOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * The BCP-47 language code of the text in the document. Read supports auto language\n   * identification and multi-language documents, so only provide a language code if you would like\n   * to force the document to be processed in that specific language. See\n   * https://aka.ms/ocr-languages for list of supported languages. Possible values include: 'af',\n   * 'ast', 'bi', 'br', 'ca', 'ceb', 'ch', 'co', 'crh', 'cs', 'csb', 'da', 'de', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fil', 'fj', 'fr', 'fur', 'fy', 'ga', 'gd', 'gil', 'gl', 'gv', 'hni', 'hsb', 'ht',\n   * 'hu', 'ia', 'id', 'it', 'iu', 'ja', 'jv', 'kaa', 'kac', 'kea', 'kha', 'kl', 'ko', 'ku', 'kw',\n   * 'lb', 'ms', 'mww', 'nap', 'nl', 'no', 'oc', 'pl', 'pt', 'quc', 'rm', 'sco', 'sl', 'sq', 'sv',\n   * 'sw', 'tet', 'tr', 'tt', 'uz', 'vo', 'wae', 'yua', 'za', 'zh-Hans', 'zh-Hant', 'zu'\n   */\n  language?: OcrDetectionLanguage;\n  /**\n   * Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want\n   * to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a\n   * comma.\n   */\n  pages?: string[];\n  /**\n   * Optional parameter to specify the version of the OCR model used for text extraction. Accepted\n   * values are: \"latest\", \"latest-preview\", \"2021-04-12\". Defaults to \"latest\". Default value:\n   * 'latest'.\n   */\n  modelVersion?: string;\n  /**\n   * Optional parameter to specify which reading order algorithm should be applied when ordering\n   * the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not\n   * specified. Default value: 'basic'.\n   */\n  readingOrder?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientAnalyzeImageInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * A string indicating what visual feature types to return. Multiple values should be\n   * comma-separated. Valid visual feature types include: Categories - categorizes image content\n   * according to a taxonomy defined in documentation. Tags - tags the image with a detailed list\n   * of words related to the image content. Description - describes the image content with a\n   * complete English sentence. Faces - detects if faces are present. If present, generate\n   * coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color\n   * - determines the accent color, dominant color, and whether an image is black&white. Adult -\n   * detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory\n   * (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also\n   * detected. Objects - detects various objects within an image, including the approximate\n   * location. The Objects argument is only available in English. Brands - detects various brands\n   * within an image, including the approximate location. The Brands argument is only available in\n   * English.\n   */\n  visualFeatures?: VisualFeatureTypes[];\n  /**\n   * A string indicating which domain-specific details to return. Multiple values should be\n   * comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if\n   * detected in the image, Landmarks - identifies notable landmarks in the image.\n   */\n  details?: Details[];\n  /**\n   * The desired language for output generation. If this parameter is not specified, the default\n   * value is \"en\". See https://aka.ms/cv-languages for list of supported languages. Possible\n   * values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n   * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n   * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'. Default value:\n   * 'en'.\n   */\n  language?: Language4;\n  /**\n   * Turn off specified domain models when generating the description.\n   */\n  descriptionExclude?: DescriptionExclude[];\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientGetAreaOfInterestInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientDescribeImageInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * Maximum number of candidate descriptions to be returned.  The default is 1. Default value: 1.\n   */\n  maxCandidates?: number;\n  /**\n   * The desired language for output generation. If this parameter is not specified, the default\n   * value is \"en\". See https://aka.ms/cv-languages for list of supported languages. Possible\n   * values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n   * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n   * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'. Default value:\n   * 'en'.\n   */\n  language?: Language5;\n  /**\n   * Turn off specified domain models when generating the description.\n   */\n  descriptionExclude?: DescriptionExclude[];\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientDetectObjectsInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientGenerateThumbnailInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * Boolean flag for enabling smart cropping. Default value: false.\n   */\n  smartCropping?: boolean;\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientAnalyzeImageByDomainInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * The desired language for output generation. If this parameter is not specified, the default\n   * value is \"en\". See https://aka.ms/cv-languages for list of supported languages. Possible\n   * values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n   * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n   * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'. Default value:\n   * 'en'.\n   */\n  language?: Language6;\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientRecognizePrintedTextInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.\n   * Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr',\n   * 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro',\n   * 'sr-Cyrl', 'sr-Latn', 'sk'. Default value: 'unk'.\n   */\n  language?: OcrLanguages;\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientTagImageInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * The desired language for output generation. If this parameter is not specified, the default\n   * value is \"en\". See https://aka.ms/cv-languages for list of supported languages. Possible\n   * values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n   * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n   * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'. Default value:\n   * 'en'.\n   */\n  language?: Language7;\n  /**\n   * Optional parameter to specify the version of the AI model. Accepted values are: \"latest\",\n   * \"2021-04-01\", \"2021-05-01\". Defaults to \"latest\". Default value: 'latest'.\n   */\n  modelVersion?: string;\n}\n\n/**\n * Optional Parameters.\n */\nexport interface ComputerVisionClientReadInStreamOptionalParams extends msRest.RequestOptionsBase {\n  /**\n   * The BCP-47 language code of the text in the document. Read supports auto language\n   * identification and multi-language documents, so only provide a language code if you would like\n   * to force the document to be processed in that specific language. See\n   * https://aka.ms/ocr-languages for list of supported languages. Possible values include: 'af',\n   * 'ast', 'bi', 'br', 'ca', 'ceb', 'ch', 'co', 'crh', 'cs', 'csb', 'da', 'de', 'en', 'es', 'et',\n   * 'eu', 'fi', 'fil', 'fj', 'fr', 'fur', 'fy', 'ga', 'gd', 'gil', 'gl', 'gv', 'hni', 'hsb', 'ht',\n   * 'hu', 'ia', 'id', 'it', 'iu', 'ja', 'jv', 'kaa', 'kac', 'kea', 'kha', 'kl', 'ko', 'ku', 'kw',\n   * 'lb', 'ms', 'mww', 'nap', 'nl', 'no', 'oc', 'pl', 'pt', 'quc', 'rm', 'sco', 'sl', 'sq', 'sv',\n   * 'sw', 'tet', 'tr', 'tt', 'uz', 'vo', 'wae', 'yua', 'za', 'zh-Hans', 'zh-Hant', 'zu'\n   */\n  language?: OcrDetectionLanguage;\n  /**\n   * Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want\n   * to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a\n   * comma.\n   */\n  pages?: string[];\n  /**\n   * Optional parameter to specify the version of the OCR model used for text extraction. Accepted\n   * values are: \"latest\", \"latest-preview\", \"2021-04-12\". Defaults to \"latest\". Default value:\n   * 'latest'.\n   */\n  modelVersion?: string;\n  /**\n   * Optional parameter to specify which reading order algorithm should be applied when ordering\n   * the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not\n   * specified. Default value: 'basic'.\n   */\n  readingOrder?: string;\n}\n\n/**\n * Defines headers for Read operation.\n */\nexport interface ReadHeaders {\n  /**\n   * URL to query for status of the operation. The operation ID will expire in 48 hours.\n   */\n  operationLocation: string;\n}\n\n/**\n * Defines headers for ReadInStream operation.\n */\nexport interface ReadInStreamHeaders {\n  /**\n   * URL to query for status of the operation. The operation ID will expire in 48 hours.\n   */\n  operationLocation: string;\n}\n\n/**\n * Defines values for Gender.\n * Possible values include: 'Male', 'Female'\n * @readonly\n * @enum {string}\n */\nexport type Gender = 'Male' | 'Female';\n\n/**\n * Defines values for ComputerVisionErrorCodes.\n * Possible values include: 'InvalidRequest', 'InvalidArgument', 'InternalServerError',\n * 'ServiceUnavailable'\n * @readonly\n * @enum {string}\n */\nexport type ComputerVisionErrorCodes = 'InvalidRequest' | 'InvalidArgument' | 'InternalServerError' | 'ServiceUnavailable';\n\n/**\n * Defines values for ComputerVisionInnerErrorCodeValue.\n * Possible values include: 'InvalidImageFormat', 'UnsupportedMediaType', 'InvalidImageUrl',\n * 'NotSupportedFeature', 'NotSupportedImage', 'Timeout', 'InternalServerError',\n * 'InvalidImageSize', 'BadArgument', 'DetectFaceError', 'NotSupportedLanguage',\n * 'InvalidThumbnailSize', 'InvalidDetails', 'InvalidModel', 'CancelledRequest',\n * 'NotSupportedVisualFeature', 'FailedToProcess', 'Unspecified', 'StorageException'\n * @readonly\n * @enum {string}\n */\nexport type ComputerVisionInnerErrorCodeValue = 'InvalidImageFormat' | 'UnsupportedMediaType' | 'InvalidImageUrl' | 'NotSupportedFeature' | 'NotSupportedImage' | 'Timeout' | 'InternalServerError' | 'InvalidImageSize' | 'BadArgument' | 'DetectFaceError' | 'NotSupportedLanguage' | 'InvalidThumbnailSize' | 'InvalidDetails' | 'InvalidModel' | 'CancelledRequest' | 'NotSupportedVisualFeature' | 'FailedToProcess' | 'Unspecified' | 'StorageException';\n\n/**\n * Defines values for OperationStatusCodes.\n * Possible values include: 'notStarted', 'running', 'failed', 'succeeded'\n * @readonly\n * @enum {string}\n */\nexport type OperationStatusCodes = 'notStarted' | 'running' | 'failed' | 'succeeded';\n\n/**\n * Defines values for TextRecognitionResultDimensionUnit.\n * Possible values include: 'pixel', 'inch'\n * @readonly\n * @enum {string}\n */\nexport type TextRecognitionResultDimensionUnit = 'pixel' | 'inch';\n\n/**\n * Defines values for TextStyle.\n * Possible values include: 'other', 'handwriting'\n * @readonly\n * @enum {string}\n */\nexport type TextStyle = 'other' | 'handwriting';\n\n/**\n * Defines values for DescriptionExclude.\n * Possible values include: 'Celebrities', 'Landmarks'\n * @readonly\n * @enum {string}\n */\nexport type DescriptionExclude = 'Celebrities' | 'Landmarks';\n\n/**\n * Defines values for OcrLanguages.\n * Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de',\n * 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl',\n * 'sr-Latn', 'sk'\n * @readonly\n * @enum {string}\n */\nexport type OcrLanguages = 'unk' | 'zh-Hans' | 'zh-Hant' | 'cs' | 'da' | 'nl' | 'en' | 'fi' | 'fr' | 'de' | 'el' | 'hu' | 'it' | 'ja' | 'ko' | 'nb' | 'pl' | 'pt' | 'ru' | 'es' | 'sv' | 'tr' | 'ar' | 'ro' | 'sr-Cyrl' | 'sr-Latn' | 'sk';\n\n/**\n * Defines values for VisualFeatureTypes.\n * Possible values include: 'ImageType', 'Faces', 'Adult', 'Categories', 'Color', 'Tags',\n * 'Description', 'Objects', 'Brands'\n * @readonly\n * @enum {string}\n */\nexport type VisualFeatureTypes = 'ImageType' | 'Faces' | 'Adult' | 'Categories' | 'Color' | 'Tags' | 'Description' | 'Objects' | 'Brands';\n\n/**\n * Defines values for OcrDetectionLanguage.\n * Possible values include: 'af', 'ast', 'bi', 'br', 'ca', 'ceb', 'ch', 'co', 'crh', 'cs', 'csb',\n * 'da', 'de', 'en', 'es', 'et', 'eu', 'fi', 'fil', 'fj', 'fr', 'fur', 'fy', 'ga', 'gd', 'gil',\n * 'gl', 'gv', 'hni', 'hsb', 'ht', 'hu', 'ia', 'id', 'it', 'iu', 'ja', 'jv', 'kaa', 'kac', 'kea',\n * 'kha', 'kl', 'ko', 'ku', 'kw', 'lb', 'ms', 'mww', 'nap', 'nl', 'no', 'oc', 'pl', 'pt', 'quc',\n * 'rm', 'sco', 'sl', 'sq', 'sv', 'sw', 'tet', 'tr', 'tt', 'uz', 'vo', 'wae', 'yua', 'za',\n * 'zh-Hans', 'zh-Hant', 'zu'\n * @readonly\n * @enum {string}\n */\nexport type OcrDetectionLanguage = 'af' | 'ast' | 'bi' | 'br' | 'ca' | 'ceb' | 'ch' | 'co' | 'crh' | 'cs' | 'csb' | 'da' | 'de' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fil' | 'fj' | 'fr' | 'fur' | 'fy' | 'ga' | 'gd' | 'gil' | 'gl' | 'gv' | 'hni' | 'hsb' | 'ht' | 'hu' | 'ia' | 'id' | 'it' | 'iu' | 'ja' | 'jv' | 'kaa' | 'kac' | 'kea' | 'kha' | 'kl' | 'ko' | 'ku' | 'kw' | 'lb' | 'ms' | 'mww' | 'nap' | 'nl' | 'no' | 'oc' | 'pl' | 'pt' | 'quc' | 'rm' | 'sco' | 'sl' | 'sq' | 'sv' | 'sw' | 'tet' | 'tr' | 'tt' | 'uz' | 'vo' | 'wae' | 'yua' | 'za' | 'zh-Hans' | 'zh-Hant' | 'zu';\n\n/**\n * Defines values for Details.\n * Possible values include: 'Celebrities', 'Landmarks'\n * @readonly\n * @enum {string}\n */\nexport type Details = 'Celebrities' | 'Landmarks';\n\n/**\n * Defines values for Language.\n * Possible values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es',\n * 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'\n * @readonly\n * @enum {string}\n */\nexport type Language = 'ar' | 'az' | 'bg' | 'bs' | 'ca' | 'cs' | 'cy' | 'da' | 'de' | 'el' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fr' | 'ga' | 'gl' | 'he' | 'hi' | 'hr' | 'hu' | 'id' | 'it' | 'ja' | 'kk' | 'ko' | 'lt' | 'lv' | 'mk' | 'ms' | 'nb' | 'nl' | 'pl' | 'prs' | 'pt' | 'pt-BR' | 'pt-PT' | 'ro' | 'ru' | 'sk' | 'sl' | 'sr-Cyrl' | 'sr-Latn' | 'sv' | 'th' | 'tr' | 'uk' | 'vi' | 'zh' | 'zh-Hans' | 'zh-Hant';\n\n/**\n * Defines values for Language1.\n * Possible values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es',\n * 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'\n * @readonly\n * @enum {string}\n */\nexport type Language1 = 'ar' | 'az' | 'bg' | 'bs' | 'ca' | 'cs' | 'cy' | 'da' | 'de' | 'el' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fr' | 'ga' | 'gl' | 'he' | 'hi' | 'hr' | 'hu' | 'id' | 'it' | 'ja' | 'kk' | 'ko' | 'lt' | 'lv' | 'mk' | 'ms' | 'nb' | 'nl' | 'pl' | 'prs' | 'pt' | 'pt-BR' | 'pt-PT' | 'ro' | 'ru' | 'sk' | 'sl' | 'sr-Cyrl' | 'sr-Latn' | 'sv' | 'th' | 'tr' | 'uk' | 'vi' | 'zh' | 'zh-Hans' | 'zh-Hant';\n\n/**\n * Defines values for Language2.\n * Possible values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es',\n * 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'\n * @readonly\n * @enum {string}\n */\nexport type Language2 = 'ar' | 'az' | 'bg' | 'bs' | 'ca' | 'cs' | 'cy' | 'da' | 'de' | 'el' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fr' | 'ga' | 'gl' | 'he' | 'hi' | 'hr' | 'hu' | 'id' | 'it' | 'ja' | 'kk' | 'ko' | 'lt' | 'lv' | 'mk' | 'ms' | 'nb' | 'nl' | 'pl' | 'prs' | 'pt' | 'pt-BR' | 'pt-PT' | 'ro' | 'ru' | 'sk' | 'sl' | 'sr-Cyrl' | 'sr-Latn' | 'sv' | 'th' | 'tr' | 'uk' | 'vi' | 'zh' | 'zh-Hans' | 'zh-Hant';\n\n/**\n * Defines values for Language3.\n * Possible values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es',\n * 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'\n * @readonly\n * @enum {string}\n */\nexport type Language3 = 'ar' | 'az' | 'bg' | 'bs' | 'ca' | 'cs' | 'cy' | 'da' | 'de' | 'el' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fr' | 'ga' | 'gl' | 'he' | 'hi' | 'hr' | 'hu' | 'id' | 'it' | 'ja' | 'kk' | 'ko' | 'lt' | 'lv' | 'mk' | 'ms' | 'nb' | 'nl' | 'pl' | 'prs' | 'pt' | 'pt-BR' | 'pt-PT' | 'ro' | 'ru' | 'sk' | 'sl' | 'sr-Cyrl' | 'sr-Latn' | 'sv' | 'th' | 'tr' | 'uk' | 'vi' | 'zh' | 'zh-Hans' | 'zh-Hant';\n\n/**\n * Defines values for Language4.\n * Possible values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es',\n * 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'\n * @readonly\n * @enum {string}\n */\nexport type Language4 = 'ar' | 'az' | 'bg' | 'bs' | 'ca' | 'cs' | 'cy' | 'da' | 'de' | 'el' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fr' | 'ga' | 'gl' | 'he' | 'hi' | 'hr' | 'hu' | 'id' | 'it' | 'ja' | 'kk' | 'ko' | 'lt' | 'lv' | 'mk' | 'ms' | 'nb' | 'nl' | 'pl' | 'prs' | 'pt' | 'pt-BR' | 'pt-PT' | 'ro' | 'ru' | 'sk' | 'sl' | 'sr-Cyrl' | 'sr-Latn' | 'sv' | 'th' | 'tr' | 'uk' | 'vi' | 'zh' | 'zh-Hans' | 'zh-Hant';\n\n/**\n * Defines values for Language5.\n * Possible values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es',\n * 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'\n * @readonly\n * @enum {string}\n */\nexport type Language5 = 'ar' | 'az' | 'bg' | 'bs' | 'ca' | 'cs' | 'cy' | 'da' | 'de' | 'el' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fr' | 'ga' | 'gl' | 'he' | 'hi' | 'hr' | 'hu' | 'id' | 'it' | 'ja' | 'kk' | 'ko' | 'lt' | 'lv' | 'mk' | 'ms' | 'nb' | 'nl' | 'pl' | 'prs' | 'pt' | 'pt-BR' | 'pt-PT' | 'ro' | 'ru' | 'sk' | 'sl' | 'sr-Cyrl' | 'sr-Latn' | 'sv' | 'th' | 'tr' | 'uk' | 'vi' | 'zh' | 'zh-Hans' | 'zh-Hant';\n\n/**\n * Defines values for Language6.\n * Possible values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es',\n * 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'\n * @readonly\n * @enum {string}\n */\nexport type Language6 = 'ar' | 'az' | 'bg' | 'bs' | 'ca' | 'cs' | 'cy' | 'da' | 'de' | 'el' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fr' | 'ga' | 'gl' | 'he' | 'hi' | 'hr' | 'hu' | 'id' | 'it' | 'ja' | 'kk' | 'ko' | 'lt' | 'lv' | 'mk' | 'ms' | 'nb' | 'nl' | 'pl' | 'prs' | 'pt' | 'pt-BR' | 'pt-PT' | 'ro' | 'ru' | 'sk' | 'sl' | 'sr-Cyrl' | 'sr-Latn' | 'sv' | 'th' | 'tr' | 'uk' | 'vi' | 'zh' | 'zh-Hans' | 'zh-Hant';\n\n/**\n * Defines values for Language7.\n * Possible values include: 'ar', 'az', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es',\n * 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt',\n * 'lv', 'mk', 'ms', 'nb', 'nl', 'pl', 'prs', 'pt', 'pt-BR', 'pt-PT', 'ro', 'ru', 'sk', 'sl',\n * 'sr-Cyrl', 'sr-Latn', 'sv', 'th', 'tr', 'uk', 'vi', 'zh', 'zh-Hans', 'zh-Hant'\n * @readonly\n * @enum {string}\n */\nexport type Language7 = 'ar' | 'az' | 'bg' | 'bs' | 'ca' | 'cs' | 'cy' | 'da' | 'de' | 'el' | 'en' | 'es' | 'et' | 'eu' | 'fi' | 'fr' | 'ga' | 'gl' | 'he' | 'hi' | 'hr' | 'hu' | 'id' | 'it' | 'ja' | 'kk' | 'ko' | 'lt' | 'lv' | 'mk' | 'ms' | 'nb' | 'nl' | 'pl' | 'prs' | 'pt' | 'pt-BR' | 'pt-PT' | 'ro' | 'ru' | 'sk' | 'sl' | 'sr-Cyrl' | 'sr-Latn' | 'sv' | 'th' | 'tr' | 'uk' | 'vi' | 'zh' | 'zh-Hans' | 'zh-Hant';\n\n/**\n * Contains response data for the analyzeImage operation.\n */\nexport type AnalyzeImageResponse = ImageAnalysis & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: ImageAnalysis;\n    };\n};\n\n/**\n * Contains response data for the describeImage operation.\n */\nexport type DescribeImageResponse = ImageDescription & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: ImageDescription;\n    };\n};\n\n/**\n * Contains response data for the detectObjects operation.\n */\nexport type DetectObjectsResponse = DetectResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: DetectResult;\n    };\n};\n\n/**\n * Contains response data for the listModels operation.\n */\nexport type ListModelsResponse = ListModelsResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: ListModelsResult;\n    };\n};\n\n/**\n * Contains response data for the analyzeImageByDomain operation.\n */\nexport type AnalyzeImageByDomainResponse = DomainModelResults & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: DomainModelResults;\n    };\n};\n\n/**\n * Contains response data for the recognizePrintedText operation.\n */\nexport type RecognizePrintedTextResponse = OcrResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: OcrResult;\n    };\n};\n\n/**\n * Contains response data for the tagImage operation.\n */\nexport type TagImageResponse = TagResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: TagResult;\n    };\n};\n\n/**\n * Contains response data for the generateThumbnail operation.\n */\nexport type GenerateThumbnailResponse = {\n  /**\n   * BROWSER ONLY\n   *\n   * The response body as a browser Blob.\n   * Always undefined in node.js.\n   */\n  blobBody?: Promise<Blob>;\n\n  /**\n   * NODEJS ONLY\n   *\n   * The response body as a node.js Readable stream.\n   * Always undefined in the browser.\n   */\n  readableStreamBody?: NodeJS.ReadableStream;\n\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse;\n};\n\n/**\n * Contains response data for the getAreaOfInterest operation.\n */\nexport type GetAreaOfInterestResponse = AreaOfInterestResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: AreaOfInterestResult;\n    };\n};\n\n/**\n * Contains response data for the read operation.\n */\nexport type ReadResponse = ReadHeaders & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The parsed HTTP response headers.\n       */\n      parsedHeaders: ReadHeaders;\n    };\n};\n\n/**\n * Contains response data for the getReadResult operation.\n */\nexport type GetReadResultResponse = ReadOperationResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: ReadOperationResult;\n    };\n};\n\n/**\n * Contains response data for the analyzeImageInStream operation.\n */\nexport type AnalyzeImageInStreamResponse = ImageAnalysis & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: ImageAnalysis;\n    };\n};\n\n/**\n * Contains response data for the getAreaOfInterestInStream operation.\n */\nexport type GetAreaOfInterestInStreamResponse = AreaOfInterestResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: AreaOfInterestResult;\n    };\n};\n\n/**\n * Contains response data for the describeImageInStream operation.\n */\nexport type DescribeImageInStreamResponse = ImageDescription & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: ImageDescription;\n    };\n};\n\n/**\n * Contains response data for the detectObjectsInStream operation.\n */\nexport type DetectObjectsInStreamResponse = DetectResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: DetectResult;\n    };\n};\n\n/**\n * Contains response data for the generateThumbnailInStream operation.\n */\nexport type GenerateThumbnailInStreamResponse = {\n  /**\n   * BROWSER ONLY\n   *\n   * The response body as a browser Blob.\n   * Always undefined in node.js.\n   */\n  blobBody?: Promise<Blob>;\n\n  /**\n   * NODEJS ONLY\n   *\n   * The response body as a node.js Readable stream.\n   * Always undefined in the browser.\n   */\n  readableStreamBody?: NodeJS.ReadableStream;\n\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse;\n};\n\n/**\n * Contains response data for the analyzeImageByDomainInStream operation.\n */\nexport type AnalyzeImageByDomainInStreamResponse = DomainModelResults & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: DomainModelResults;\n    };\n};\n\n/**\n * Contains response data for the recognizePrintedTextInStream operation.\n */\nexport type RecognizePrintedTextInStreamResponse = OcrResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: OcrResult;\n    };\n};\n\n/**\n * Contains response data for the tagImageInStream operation.\n */\nexport type TagImageInStreamResponse = TagResult & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The response body as text (string format)\n       */\n      bodyAsText: string;\n\n      /**\n       * The response body as parsed JSON or XML\n       */\n      parsedBody: TagResult;\n    };\n};\n\n/**\n * Contains response data for the readInStream operation.\n */\nexport type ReadInStreamResponse = ReadInStreamHeaders & {\n  /**\n   * The underlying HTTP response.\n   */\n  _response: msRest.HttpResponse & {\n      /**\n       * The parsed HTTP response headers.\n       */\n      parsedHeaders: ReadInStreamHeaders;\n    };\n};\n"]},"metadata":{},"sourceType":"script","externalDependencies":[]}